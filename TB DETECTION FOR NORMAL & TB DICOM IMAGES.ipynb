{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fd16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c132d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "random_seed = 42  # You can choose any seed value\n",
    "\n",
    "# Set the random seed for NumPy\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Set the random seed for TensorFlow\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224228aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pydicom\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47bdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuberculosis_dir = r\"C:\\Users\\kande\\OneDrive\\Desktop\\TuberClosis\\intbtr254\"\n",
    "normal_dir = r\"C:\\Users\\kande\\OneDrive\\Desktop\\TuberClosis\\intbtr105\\intbtr105\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0567144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess_images(directory, image_size=(224, 224)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".dicom\"):\n",
    "            dcm = pydicom.dcmread(os.path.join(directory, filename))\n",
    "            image = dcm.pixel_array  # Get pixel data\n",
    "            image = tf.image.resize(tf.expand_dims(image, axis=-1), image_size)  # Expand dimensions and resize\n",
    "            image = tf.image.grayscale_to_rgb(image)  # Convert to RGB\n",
    "            images.append(image)\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30e7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuberculosis_images = load_and_preprocess_images(tuberculosis_dir)\n",
    "normal_images = load_and_preprocess_images(normal_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a4c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tuberculosis_images) == 0 or len(normal_images) == 0:\n",
    "    raise ValueError(\"Ensure that both classes have images in the specified directories.\")\n",
    "\n",
    "# Split data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed2a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((tuberculosis_images, normal_images))\n",
    "y = np.concatenate((np.ones(len(tuberculosis_images)), np.zeros(len(normal_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4dcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0689a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAccuracyMetric(Metric):\n",
    "    def __init__(self, name=\"custom_accuracy\", **kwargs):\n",
    "        super(CustomAccuracyMetric, self).__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        correct = tf.cast(tf.equal(y_true, tf.round(y_pred)), tf.float32)\n",
    "        self.total.assign_add(tf.reduce_sum(correct))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ad02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Improved CNN Model Architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.5),  # Add Dropout layer\n",
    "    BatchNormalization(),  # Add BatchNormalization layer\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# ... (Remaining code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065f70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[CustomAccuracyMetric()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77508b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_custom_accuracy\", patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9177fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7353 - custom_accuracy: 0.5536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kande\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 18s 1s/step - loss: 0.7353 - custom_accuracy: 0.5536 - val_loss: 0.8336 - val_custom_accuracy: 0.5814\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6985 - custom_accuracy: 0.5681 - val_loss: 0.8135 - val_custom_accuracy: 0.6047\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.6799 - custom_accuracy: 0.5710 - val_loss: 0.8163 - val_custom_accuracy: 0.5814\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.6805 - custom_accuracy: 0.5652 - val_loss: 0.7671 - val_custom_accuracy: 0.5814\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.6479 - custom_accuracy: 0.6116 - val_loss: 0.6728 - val_custom_accuracy: 0.5814\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.6347 - custom_accuracy: 0.6319 - val_loss: 0.6317 - val_custom_accuracy: 0.5814\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.5855 - custom_accuracy: 0.7043 - val_loss: 0.5722 - val_custom_accuracy: 0.6977\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.6308 - custom_accuracy: 0.6812 - val_loss: 0.6085 - val_custom_accuracy: 0.5814\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.6173 - custom_accuracy: 0.6928 - val_loss: 0.6340 - val_custom_accuracy: 0.5814\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6139 - custom_accuracy: 0.6696 - val_loss: 0.6100 - val_custom_accuracy: 0.5814\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.6262 - custom_accuracy: 0.6609 - val_loss: 1.6380 - val_custom_accuracy: 0.4186\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 10s 924ms/step - loss: 0.6405 - custom_accuracy: 0.6319 - val_loss: 0.5785 - val_custom_accuracy: 0.6977\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 10s 890ms/step - loss: 0.6331 - custom_accuracy: 0.6609 - val_loss: 0.5892 - val_custom_accuracy: 0.6047\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 10s 891ms/step - loss: 0.6299 - custom_accuracy: 0.6493 - val_loss: 0.5924 - val_custom_accuracy: 0.6279\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 10s 916ms/step - loss: 0.6098 - custom_accuracy: 0.6551 - val_loss: 0.7756 - val_custom_accuracy: 0.4186\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 11s 949ms/step - loss: 0.6389 - custom_accuracy: 0.6493 - val_loss: 0.5130 - val_custom_accuracy: 0.8140\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 10s 911ms/step - loss: 0.6511 - custom_accuracy: 0.6348 - val_loss: 0.5452 - val_custom_accuracy: 0.7907\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 11s 951ms/step - loss: 0.6384 - custom_accuracy: 0.6232 - val_loss: 0.5661 - val_custom_accuracy: 0.8372\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 10s 904ms/step - loss: 0.6403 - custom_accuracy: 0.6493 - val_loss: 0.5489 - val_custom_accuracy: 0.6977\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 10s 895ms/step - loss: 0.6289 - custom_accuracy: 0.6522 - val_loss: 0.5655 - val_custom_accuracy: 0.6279\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6147 - custom_accuracy: 0.6522 - val_loss: 0.5561 - val_custom_accuracy: 0.7442\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.6153 - custom_accuracy: 0.6899 - val_loss: 0.5481 - val_custom_accuracy: 0.7442\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6373 - custom_accuracy: 0.6609 - val_loss: 0.5475 - val_custom_accuracy: 0.7674\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6086 - custom_accuracy: 0.6957 - val_loss: 0.6000 - val_custom_accuracy: 0.7442\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6325 - custom_accuracy: 0.6812 - val_loss: 0.5541 - val_custom_accuracy: 0.6977\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6161 - custom_accuracy: 0.6667 - val_loss: 0.5710 - val_custom_accuracy: 0.8140\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 11s 978ms/step - loss: 0.6298 - custom_accuracy: 0.6899 - val_loss: 0.5576 - val_custom_accuracy: 0.6279\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 11s 937ms/step - loss: 0.6062 - custom_accuracy: 0.6899 - val_loss: 0.5499 - val_custom_accuracy: 0.6977\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_val, y_val), epochs=50, callbacks=[early_stopping, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efe3cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 147ms/step - loss: 0.5993 - custom_accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_custom_accuracy = model.evaluate(X_test, y_test)\n",
    "model.save(\"tuberculosis_detection_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e549b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tuberculosis_single_image(model, image_path):\n",
    "    # Read the DICOM image\n",
    "    dcm = pydicom.dcmread(image_path)\n",
    "    image = dcm.pixel_array\n",
    "\n",
    "    # Ensure that the image has a channel dimension\n",
    "    if len(image.shape) == 2:\n",
    "        image = image[:, :, np.newaxis]\n",
    "\n",
    "    # Expand dimensions to make it 4D\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    # Resize the image to the model's input shape (224, 224, 3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    \n",
    "    # Convert to RGB\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    image = image / 255.0  # Normalize pixel values if needed\n",
    "\n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(image)\n",
    "\n",
    "    # Interpret the prediction as needed for your specific model\n",
    "\n",
    "    return prediction  # Adjust this line to return the appropriate result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "288e77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 311ms/step\n"
     ]
    }
   ],
   "source": [
    "result = detect_tuberculosis_single_image(model, r\"C:\\Users\\kande\\Downloads\\intbtr254\\intbtr254\\cc730ec065ec6d9e85f2b5cf153d7fd9_Abnormal.dicom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29f92430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "Tuberculosis is detected\n",
      "[[0.5304645]]\n"
     ]
    }
   ],
   "source": [
    "result = detect_tuberculosis_single_image(model, r\"C:\\Users\\kande\\Downloads\\intbtr254\\intbtr254\\cc730ec065ec6d9e85f2b5cf153d7fd9_Abnormal.dicom\")\n",
    "# Assuming 'result' is a probability score\n",
    "threshold = 0.5\n",
    "if result >= threshold:\n",
    "    print(\"Tuberculosis is detected\")\n",
    "else:\n",
    "    print(\"Tuberculosis is not detected\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27891141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
